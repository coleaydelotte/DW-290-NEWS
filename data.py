import pandas as pd

def get_unique_values(series):
    vals = series.dropna().unique()
    return sorted(list(vals))

data = pd.read_csv('all_articles_summary.csv')
print(data.head())
print("---" * 25)
print(data.shape)
print("---" * 25)
print(data["Title"].isnull().sum())
print("---" * 25)
print(data["Language"].value_counts())
print("---" * 25)
print(data["DomainRank"].value_counts())
print("---" * 25)
print(data['Site'].value_counts())
print("---" * 25)
print(data['Author'].value_counts())
print("---" * 25)
data['Participants'] = pd.to_numeric(data['Participants'], errors='coerce')
print("---" * 25)
print(data.groupby('Site')['Participants'].mean().sort_values(ascending=False))
print("---" * 25)
print(data.isna().sum().sort_values(ascending=False))
print("---" * 25)
print(data[data.isna().any(axis=1)])
print("---" * 25)
print(data[data.isna().sum(axis=1) > 1])
print("---" * 25)
print(data.groupby("Language")["URL"].count().reset_index(name="FakeNewsCount").sort_values("FakeNewsCount", ascending=False))
print("---" * 25)
authors_countries = data.groupby("Author")["Country"].apply(get_unique_values).reset_index(name="CountriesPublishedIn")
print(authors_countries.head())
print(authors_countries["CountriesPublishedIn"].value_counts())
print("---" * 25)
authors_languages = data.groupby("Author")["Language"].apply(get_unique_values).reset_index(name="LanguagesUsed")
print(authors_languages.head())
print(authors_languages["LanguagesUsed"].value_counts())
print("---" * 25)
print(data.groupby("Site")["URL"].count().reset_index(name="FakeNewsCount").sort_values("FakeNewsCount", ascending=False))
